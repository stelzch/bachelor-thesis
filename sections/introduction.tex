\chapter{Introduction}
\label{ch:Introduction}

\section{Motivation}
\label{sec:Motivation}
A common problem in massively parallel computations is the reduction (e.g. summation) of results over the entire cluster.
RAxML-NG \cite{kozlov_raxml-ng_2019-1} for example is a software package that estimates phylogenetic trees based on a
multiple sequence alignment (MSA) from different taxa. Given the exponentially large number of possible trees
(for $100$ taxa there exist over $10^{182}$ distinct phylogenies \cite{stamatakis_efficient_2020}) and 
proven $\mathcal{NP}$-hardness of the problem \cite{roch_short_2006}, a complete tree search is infeasible.
Instead, RAxML-NG uses stochastic evolutionary models to determine the likelihood of a given tree and performs
a tree search to find a maximum likelihood estimate. The likelihood values are given logarithmically, since they
are extremely small.
Because different sites are assumed to evolve independently from one another, RAxML-NG computes per-site likelihoods
in parallel on different threads. The overall likelihood of a tree is the product of all per-site likelihoods, therefore
the tree log-likelihood is the sum of all per-site log-likelihoods (PSLLH):
\begin{align}
L_{\textrm{tree}} &= \prod_{s \in \textrm{sites}} L_s \\
\label{eq:llh_sum}
\log L_{\textrm{tree}} &= \log (\prod_{s \in \textrm{sites}} L_s) = \sum_{s \in \textrm{sites}}  \log L_s
\end{align}
During the tree search, the log-likelihoods determine how a tree is altered in order to further increase its likelihood.
Therefore, the correctness of sum \eqref{eq:llh_sum} is critically important for the resulting trees.
RAxML-NG uses floating-point numbers to represent LLH values, but floating-point arithmetic is not necessarily associative
due to rounding errors \cite{goldberg_what_1991}. Darriba et al. have shown that executing the same version of
RAxML with the same input data and random seed can still produce different trees if the number of threads is varied,
because of the different summation orders \cite{darriba_state_2018}.

%

%
%In recent years, concerns about a scientific reproducibility crisis have been expressed. In a survey \cite{baker_reproducibility_2016}
%conducted by Nature in 2016, $52\%$ of scientists believed there was a significant reproducibility crisis.
%Although some researchers argue that the problem is blown out of proportion \cite{fanelli_opinion_2018}, increasing the tangibility
%of scientific findings can only help to solidify the common base, which is becoming ever more important during a trend of
%increasing specialization.
%
%In computational biology for instance, the tool RAxML-NG \cite{kozlov_raxml-ng_2019-1} can compute maximum-likelihood estimates 
%of phylogenetic trees. Given a multiple sequence alignment (MSA), RAxML-NG iteratively alters a starting tree to maximize its likelihood
%according to a stochastic evolutionary model.
%
%Shen et al. found that even after pinning down the non-deterministic components of the
%code by specifying the random seed, $13\%$ of single-gene phylogenies were irreproducible \cite{shen_investigation_2020}.


\section{Preliminaries}
Let $\F$ be the set of floating-point numbers. Given
\begin{itemize}
\item a cluster of $p$ processing elements (PEs) indexed with $i \in \{0, \ldots, p - 1\}$
\item $n_i$ floating-point numbers per PE ($N := \sum_{i=0}^{p-1} n_i$ in total)
\item a not necessarily associative binary operation $\circ: \F \times \F \rightarrow \F$
\end{itemize}
we want to reduce all numbers by means of $\circ$ so that the end result is only dependent
on $N$ and not on $p$.

\label{sec:Preliminaries}